{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('indian_liver_patient.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.007529</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>-0.086883</td>\n",
       "      <td>-0.019910</td>\n",
       "      <td>-0.187461</td>\n",
       "      <td>-0.265924</td>\n",
       "      <td>-0.216408</td>\n",
       "      <td>-0.137351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <td>0.011763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874618</td>\n",
       "      <td>0.206669</td>\n",
       "      <td>0.214065</td>\n",
       "      <td>0.237831</td>\n",
       "      <td>-0.008099</td>\n",
       "      <td>-0.222250</td>\n",
       "      <td>-0.206267</td>\n",
       "      <td>-0.220208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <td>0.007529</td>\n",
       "      <td>0.874618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.234939</td>\n",
       "      <td>0.233894</td>\n",
       "      <td>0.257544</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.228531</td>\n",
       "      <td>-0.200125</td>\n",
       "      <td>-0.246046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.206669</td>\n",
       "      <td>0.234939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125680</td>\n",
       "      <td>0.167196</td>\n",
       "      <td>-0.028514</td>\n",
       "      <td>-0.165453</td>\n",
       "      <td>-0.234166</td>\n",
       "      <td>-0.184866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <td>-0.086883</td>\n",
       "      <td>0.214065</td>\n",
       "      <td>0.233894</td>\n",
       "      <td>0.125680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.791966</td>\n",
       "      <td>-0.042518</td>\n",
       "      <td>-0.029742</td>\n",
       "      <td>-0.002375</td>\n",
       "      <td>-0.163416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <td>-0.019910</td>\n",
       "      <td>0.237831</td>\n",
       "      <td>0.257544</td>\n",
       "      <td>0.167196</td>\n",
       "      <td>0.791966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025645</td>\n",
       "      <td>-0.085290</td>\n",
       "      <td>-0.070040</td>\n",
       "      <td>-0.151934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total_Protiens</th>\n",
       "      <td>-0.187461</td>\n",
       "      <td>-0.008099</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.028514</td>\n",
       "      <td>-0.042518</td>\n",
       "      <td>-0.025645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784053</td>\n",
       "      <td>0.234887</td>\n",
       "      <td>0.035008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albumin</th>\n",
       "      <td>-0.265924</td>\n",
       "      <td>-0.222250</td>\n",
       "      <td>-0.228531</td>\n",
       "      <td>-0.165453</td>\n",
       "      <td>-0.029742</td>\n",
       "      <td>-0.085290</td>\n",
       "      <td>0.784053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689632</td>\n",
       "      <td>0.161388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <td>-0.216408</td>\n",
       "      <td>-0.206267</td>\n",
       "      <td>-0.200125</td>\n",
       "      <td>-0.234166</td>\n",
       "      <td>-0.002375</td>\n",
       "      <td>-0.070040</td>\n",
       "      <td>0.234887</td>\n",
       "      <td>0.689632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.163131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <td>-0.137351</td>\n",
       "      <td>-0.220208</td>\n",
       "      <td>-0.246046</td>\n",
       "      <td>-0.184866</td>\n",
       "      <td>-0.163416</td>\n",
       "      <td>-0.151934</td>\n",
       "      <td>0.035008</td>\n",
       "      <td>0.161388</td>\n",
       "      <td>0.163131</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Age  Total_Bilirubin  Direct_Bilirubin  \\\n",
       "Age                         1.000000         0.011763          0.007529   \n",
       "Total_Bilirubin             0.011763         1.000000          0.874618   \n",
       "Direct_Bilirubin            0.007529         0.874618          1.000000   \n",
       "Alkaline_Phosphotase        0.080425         0.206669          0.234939   \n",
       "Alamine_Aminotransferase   -0.086883         0.214065          0.233894   \n",
       "Aspartate_Aminotransferase -0.019910         0.237831          0.257544   \n",
       "Total_Protiens             -0.187461        -0.008099         -0.000139   \n",
       "Albumin                    -0.265924        -0.222250         -0.228531   \n",
       "Albumin_and_Globulin_Ratio -0.216408        -0.206267         -0.200125   \n",
       "Dataset                    -0.137351        -0.220208         -0.246046   \n",
       "\n",
       "                            Alkaline_Phosphotase  Alamine_Aminotransferase  \\\n",
       "Age                                     0.080425                 -0.086883   \n",
       "Total_Bilirubin                         0.206669                  0.214065   \n",
       "Direct_Bilirubin                        0.234939                  0.233894   \n",
       "Alkaline_Phosphotase                    1.000000                  0.125680   \n",
       "Alamine_Aminotransferase                0.125680                  1.000000   \n",
       "Aspartate_Aminotransferase              0.167196                  0.791966   \n",
       "Total_Protiens                         -0.028514                 -0.042518   \n",
       "Albumin                                -0.165453                 -0.029742   \n",
       "Albumin_and_Globulin_Ratio             -0.234166                 -0.002375   \n",
       "Dataset                                -0.184866                 -0.163416   \n",
       "\n",
       "                            Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "Age                                          -0.019910       -0.187461   \n",
       "Total_Bilirubin                               0.237831       -0.008099   \n",
       "Direct_Bilirubin                              0.257544       -0.000139   \n",
       "Alkaline_Phosphotase                          0.167196       -0.028514   \n",
       "Alamine_Aminotransferase                      0.791966       -0.042518   \n",
       "Aspartate_Aminotransferase                    1.000000       -0.025645   \n",
       "Total_Protiens                               -0.025645        1.000000   \n",
       "Albumin                                      -0.085290        0.784053   \n",
       "Albumin_and_Globulin_Ratio                   -0.070040        0.234887   \n",
       "Dataset                                      -0.151934        0.035008   \n",
       "\n",
       "                             Albumin  Albumin_and_Globulin_Ratio   Dataset  \n",
       "Age                        -0.265924                   -0.216408 -0.137351  \n",
       "Total_Bilirubin            -0.222250                   -0.206267 -0.220208  \n",
       "Direct_Bilirubin           -0.228531                   -0.200125 -0.246046  \n",
       "Alkaline_Phosphotase       -0.165453                   -0.234166 -0.184866  \n",
       "Alamine_Aminotransferase   -0.029742                   -0.002375 -0.163416  \n",
       "Aspartate_Aminotransferase -0.085290                   -0.070040 -0.151934  \n",
       "Total_Protiens              0.784053                    0.234887  0.035008  \n",
       "Albumin                     1.000000                    0.689632  0.161388  \n",
       "Albumin_and_Globulin_Ratio  0.689632                    1.000000  0.163131  \n",
       "Dataset                     0.161388                    0.163131  1.000000  "
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.iloc[: , [0,1,3,4,5,6,7,9]].values\n",
    "y = dataset.iloc[: , -1].values\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
    "imputer = imputer.fit(X)\n",
    "X = imputer.transform(X)\n",
    "\n",
    "dataset.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "y_train = y_train-1\n",
    "y_test = y_test-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[78  0]\n",
      " [39  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred1)\n",
    "print(cm)\n",
    "accuracy_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=15, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 15, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72  6]\n",
      " [33  6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred2)\n",
    "print(cm)\n",
    "accuracy_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32 46]\n",
      " [ 1 38]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5982905982905983"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred3)\n",
    "print(cm)\n",
    "accuracy_score(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=23,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 23\n",
    "                                    , criterion = 'entropy',random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72  6]\n",
      " [30  9]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6923076923076923"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred4)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nishith\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[73  5]\n",
      " [34  5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred5)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
